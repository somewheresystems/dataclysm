{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I suggest using Python 3.10 in a conda environment with this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='image.png') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Wikipedia Database + Index\n",
    "This process takes 2x as much time as arXiv to download, about ~12 minutes to index (M3 Max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from FlagEmbedding import FlagModel\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import psutil\n",
    "\n",
    "def print_memory_usage():\n",
    "    print(f\"Current memory usage: {psutil.Process().memory_info().rss / 1024 ** 2} MB\")\n",
    "\n",
    "print(\"Loading dataset...\")\n",
    "print_memory_usage()\n",
    "dataclysm_wikipedia = load_dataset('somewheresystems/dataclysm-wikipedia', split=\"train\")\n",
    "print_memory_usage()\n",
    "\n",
    "# Check the structure of the dataset, particularly the 'title_embedding' and 'abstract_embedding' columns\n",
    "print(dataclysm_wikipedia)\n",
    "print(dataclysm_wikipedia.column_names)\n",
    "print(dataclysm_wikipedia.features)\n",
    "print_memory_usage()\n",
    "\n",
    "# Define a function to flatten the embeddings and add FAISS index\n",
    "def flatten_and_add_faiss_index(dataset, column_name):\n",
    "    embedding_shape = np.array(dataset[0][column_name]).shape\n",
    "    if len(embedding_shape) == 2:\n",
    "        print(f\"Flattening {column_name} and adding FAISS index...\")\n",
    "        # Flatten the column before adding the FAISS index\n",
    "        dataset = dataset.map(lambda x: {column_name: np.concatenate(x[column_name])})\n",
    "        dataset = dataset.add_faiss_index(column=column_name)\n",
    "        print(f\"FAISS index for {column_name} added.\")\n",
    "    else:\n",
    "        print(f\"Cannot add FAISS index for {column_name}.\")\n",
    "    print_memory_usage()\n",
    "    return dataset\n",
    "\n",
    "# Add FAISS indices for 'title_embedding' and 'abstract_embedding' and save them to different datasets\n",
    "dataclysm_wikipedia_indexed = flatten_and_add_faiss_index(dataclysm_wikipedia, 'title_embedding')\n",
    "print_memory_usage()\n",
    "\n",
    "print(\"Datasets loaded.\")\n",
    "\n",
    "# Define the model\n",
    "print(\"Initializing model...\")\n",
    "model = FlagModel('BAAI/bge-small-en-v1.5', \n",
    "                  query_instruction_for_retrieval=\"Write a representation of the following query which is optimized for using a similarity search for retrieval:\",\n",
    "                  use_fp16=True)\n",
    "print(\"Model initialized.\")\n",
    "print_memory_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize arXiv Abstract + Title Indices\n",
    "This process takes ~15 minutes to index (M3 Max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from FlagEmbedding import FlagModel\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import psutil\n",
    "\n",
    "def print_memory_usage():\n",
    "    print(f\"Current memory usage: {psutil.Process().memory_info().rss / 1024 ** 2} MB\")\n",
    "\n",
    "print(\"Loading dataset...\")\n",
    "print_memory_usage()\n",
    "dataclysm_arxiv = load_dataset('somewheresystems/dataclysm-arxiv', split=\"train\")\n",
    "print_memory_usage()\n",
    "\n",
    "# Check the structure of the dataset, particularly the 'title_embedding' and 'abstract_embedding' columns\n",
    "print(dataclysm_arxiv)\n",
    "print(dataclysm_arxiv.column_names)\n",
    "print(dataclysm_arxiv.features)\n",
    "print_memory_usage()\n",
    "\n",
    "# Define a function to flatten the embeddings and add FAISS index\n",
    "def flatten_and_add_faiss_index(dataset, column_name):\n",
    "    embedding_shape = np.array(dataset[0][column_name]).shape\n",
    "    if len(embedding_shape) == 2:\n",
    "        print(f\"Flattening {column_name} and adding FAISS index...\")\n",
    "        # Flatten the column before adding the FAISS index\n",
    "        dataset = dataset.map(lambda x: {column_name: np.concatenate(x[column_name])})\n",
    "        dataset = dataset.add_faiss_index(column=column_name)\n",
    "        print(f\"FAISS index for {column_name} added.\")\n",
    "    else:\n",
    "        print(f\"Cannot add FAISS index for {column_name}.\")\n",
    "    print_memory_usage()\n",
    "    return dataset\n",
    "\n",
    "# Add FAISS indices for 'title_embedding' and 'abstract_embedding' and save them to different datasets\n",
    "dataclysm_title_indexed = flatten_and_add_faiss_index(dataclysm_arxiv, 'title_embedding')\n",
    "dataclysm_abstract_indexed = flatten_and_add_faiss_index(dataclysm_arxiv, 'abstract_embedding')\n",
    "print_memory_usage()\n",
    "\n",
    "print(\"Datasets loaded.\")\n",
    "\n",
    "# Define the model\n",
    "print(\"Initializing model...\")\n",
    "model = FlagModel('BAAI/bge-small-en-v1.5', \n",
    "                  query_instruction_for_retrieval=\"Write a representation of the following query which is optimized for using a similarity search for retrieval:\",\n",
    "                  use_fp16=True)\n",
    "print(\"Model initialized.\")\n",
    "print_memory_usage()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  arXiv Composite Search with regex Rerank\n",
    "Search by both Abstract and Title similarity, rank both descending by score. \n",
    "1. If a duplicate (title and abstract hit) is found, it increases the score by a factor of 2. \n",
    "2. If regex finds the query in the abstract, it increases the score by 0.1 (additive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Attention Is All You Need\"\n",
    "print(\"Encoding query...\")\n",
    "query_embedding = model.encode([query])\n",
    "print(\"Query encoded.\")\n",
    "\n",
    "print(\"Retrieving examples by abstract similarity...\")\n",
    "scores_abstract, retrieved_examples_abstract = dataclysm_abstract_indexed.get_nearest_examples('abstract_embedding', query_embedding, k=10)\n",
    "print(\"Examples retrieved.\")\n",
    "\n",
    "print(\"Retrieving examples by title similarity...\")\n",
    "scores_title, retrieved_examples_title = dataclysm_title_indexed.get_nearest_examples('title_embedding', query_embedding, k=10)\n",
    "print(\"Examples retrieved.\")\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Convert retrieved examples to DataFrame\n",
    "df_abstract = pd.DataFrame(retrieved_examples_abstract)\n",
    "df_title = pd.DataFrame(retrieved_examples_title)\n",
    "\n",
    "# Calculate similarity score in percentage\n",
    "df_abstract['similarity_score'] = scores_abstract\n",
    "df_title['similarity_score'] = scores_title\n",
    "\n",
    "# Add a column to denote the source of retrieval\n",
    "df_abstract['source'] = 'A'\n",
    "df_title['source'] = 'T'\n",
    "\n",
    "# Drop 'title_embedding' and 'abstract_embedding' columns\n",
    "df_abstract = df_abstract.drop(columns=['title_embedding', 'abstract_embedding'])\n",
    "df_title = df_title.drop(columns=['title_embedding', 'abstract_embedding'])\n",
    "\n",
    "# Drop empty columns\n",
    "df_abstract = df_abstract.dropna(axis=1, how='all')\n",
    "df_title = df_title.dropna(axis=1, how='all')\n",
    "\n",
    "# Create a \"click to expand\" for the abstract so it doesn't take up much space\n",
    "df_abstract['abstract'] = df_abstract['abstract'].apply(lambda x: f'<details><summary>Abstract</summary>{x}</details>')\n",
    "df_title['abstract'] = df_title['abstract'].apply(lambda x: f'<details><summary>Abstract</summary>{x}</details>')\n",
    "\n",
    "# Create a URL field with a hyperlink which is constructed by appending the id onto the end of arxiv.org/abs/\n",
    "df_abstract['URL'] = df_abstract['id'].apply(lambda x: f'<a href=\"https://arxiv.org/abs/{x}\">Link</a>')\n",
    "df_title['URL'] = df_title['id'].apply(lambda x: f'<a href=\"https://arxiv.org/abs/{x}\">Link</a>')\n",
    "\n",
    "# Concatenate the two dataframes\n",
    "df = pd.concat([df_abstract, df_title])\n",
    "\n",
    "# Normalize the similarity score to be between 0 and 1\n",
    "df['similarity_score'] = df['similarity_score'] / df['similarity_score'].max()\n",
    "\n",
    "# Increase the score if the query is found in the abstract\n",
    "df['similarity_score'] = df.apply(lambda row: row['similarity_score'] + 0.1 if re.search(query, row['abstract'], re.IGNORECASE) else row['similarity_score'], axis=1)\n",
    "\n",
    "# Remove duplicates\n",
    "df = df.drop_duplicates(subset=['id'])\n",
    "\n",
    "# Sort by ascending similarity score\n",
    "df = df.sort_values(by='similarity_score', ascending=False)\n",
    "\n",
    "# Display the DataFrame\n",
    "from IPython.display import Markdown, display\n",
    "display(Markdown(f'QUERY: **{query}**'))\n",
    "display(HTML(df.to_html(escape=False)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wikipedia simple search (Title)\n",
    "Searches for a Wikipedia article based on title similarity to query. Useful for looking up terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Retrieval Augmented Generation\"\n",
    "print(\"Encoding query...\")\n",
    "query_embedding = model.encode([query])\n",
    "print(\"Query encoded.\")\n",
    "\n",
    "print(\"Retrieving examples by title similarity...\")\n",
    "scores, retrieved_examples = dataclysm_wikipedia_indexed.get_nearest_examples('title_embedding', query_embedding, k=10)\n",
    "print(\"Examples retrieved.\")\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "import pandas as pd\n",
    "\n",
    "# Convert retrieved examples to DataFrame\n",
    "df = pd.DataFrame(retrieved_examples)\n",
    "\n",
    "# Calculate similarity score in percentage\n",
    "df['similarity_score'] = scores\n",
    "\n",
    "\n",
    "# Drop 'title_embedding' and 'abstract_embedding' columns\n",
    "df = df.drop(columns=['title_embedding'])\n",
    "\n",
    "# Drop empty columns\n",
    "df = df.dropna(axis=1, how='all')\n",
    "\n",
    "# Create a \"click to expand\" for the abstract so it doesn't take up much space\n",
    "df['text'] = df['text'].apply(lambda x: f'<details><summary>Article Text</summary>{x}</details>')\n",
    "\n",
    "\n",
    "# Create a URL field with a hyperlink \n",
    "df['url'] = df['url'].apply(lambda x: f'<a href=\"{url}\">Link</a>')\n",
    "\n",
    "# Sort by ascending similarity score\n",
    "df = df.sort_values(by='similarity_score', ascending=False)\n",
    "\n",
    "# Display the DataFrame\n",
    "from IPython.display import Markdown, display\n",
    "display(Markdown(f'QUERY: **{query}**'))\n",
    "display(HTML(df.to_html(escape=False)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download OpenHermes-2.5-Mistral-7B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install huggingface-cli\n",
    "!huggingface-cli download TheBloke/OpenHermes-2.5-Mistral-7B-GGUF openhermes-2.5-mistral-7b.Q4_K_M.gguf --local-dir . --local-dir-use-symlinks False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval Augmented Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cpp import Llama\n",
    "from llama_cpp import LlamaGrammar\n",
    "import pandas as pd\n",
    "import json\n",
    "import httpx\n",
    "\n",
    "model = \"openhermes-2.5-mistral-7b.Q4_K_M.gguf\"\n",
    "prompt = f\"{df[['id', 'title', 'abstract']].to_html(escape=False)} ### Instruction: Use the information above to answer the query: EXPLAIN {query} ### Response:\"\n",
    "\n",
    "\n",
    "llm = Llama(model_path=model, n_ctx=8096, last_n_tokens_size=256, n_threads=4, n_gpu_layers=0)\n",
    "\n",
    "stream = llm.create_completion(prompt, stream=True, repeat_penalty=1.1, max_tokens=256, stop=[\"\\n\"], echo=False, temperature=0, mirostat_mode = 2, mirostat_tau=4.0, mirostat_eta=1.1)\n",
    "result = \"\"\n",
    "for output in stream:\n",
    "    result += output['choices'][0]['text']\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rerank results using an LLM (experimental)\n",
    "This uses LLaMA grammars / llama.cpp to return back a list instructing the LLM to rerank and drop irrelevant results. May or may not work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cpp import Llama\n",
    "from llama_cpp import LlamaGrammar\n",
    "import pandas as pd\n",
    "import json\n",
    "import httpx\n",
    "grammar_text = httpx.get(\"https://raw.githubusercontent.com/ggerganov/llama.cpp/master/grammars/json_arr.gbnf\").text\n",
    "grammar = LlamaGrammar.from_string(grammar_text)\n",
    "\n",
    "model = \"openhermes-2.5-mistral-7b.Q4_K_M.gguf\"\n",
    "prompt = f\"\"\"You are an expert at generating valid JSON.\n",
    "###\n",
    "Instruction:\n",
    "Return a valid JSON Array containing arXiv ['id'] field reranked according to how relevant the result is to the query based on its other columns at that ['id']. Drop any items that are not relevant to the query. Return just an array of the IDs, like [x,y,z] and so on in the correct order:\n",
    "        INDEX: {df[['id', 'title', 'abstract']].to_html(escape=False)}\n",
    "        QUERY: {query}\n",
    "        Take a deep breath, and solve the problem step-by-step.\n",
    "###\n",
    "Response:\"\"\"\n",
    "\n",
    "\n",
    "llm = Llama(model_path=model, n_ctx=8096, last_n_tokens_size=256, n_threads=4, n_gpu_layers=0)\n",
    "\n",
    "    \n",
    "stream = llm.create_completion(prompt, stream=True, repeat_penalty=1.1, max_tokens=256, stop=[\"]\"], echo=False, temperature=0, mirostat_mode = 2, mirostat_tau=4.0, mirostat_eta=1.1, grammar=grammar)\n",
    "result = \"\"\n",
    "for output in stream:\n",
    "    result += output['choices'][0]['text']\n",
    "\n",
    "result = result + \"]\"\n",
    "\n",
    "# Check if the result is a string, an array string, or a single ID in an array and convert it to a list of IDs\n",
    "if isinstance(result, str):\n",
    "    result_ids = [result.strip('[]')]\n",
    "elif isinstance(result, list):\n",
    "    if isinstance(result[0], str):\n",
    "        result_ids = [json.loads(res) for res in result]\n",
    "    else:\n",
    "        result_ids = result\n",
    "# Print the result\n",
    "print(result_ids)\n",
    "import re\n",
    "\n",
    "# Extract IDs from the potentially broken string using regex\n",
    "result_ids = re.findall(r'\"(.*?)\"', result_ids[0])\n",
    "\n",
    "# Filter the dataframe to only include rows with IDs in the result\n",
    "filtered_df = df[df['id'].isin(result_ids)]\n",
    "\n",
    "# Create a categorical type for sorting based on the order in result_ids\n",
    "filtered_df['id'] = pd.Categorical(filtered_df['id'], categories=result_ids, ordered=True)\n",
    "\n",
    "# Sort the dataframe based on the 'id' column\n",
    "filtered_df = filtered_df.sort_values('id')\n",
    "\n",
    "# Drop the similarity score column\n",
    "filtered_df = filtered_df.drop(columns=['similarity_score'])\n",
    "\n",
    "# Display the filtered dataframe as a table with hyperlinks\n",
    "display(HTML(filtered_df.to_html(escape=False)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
